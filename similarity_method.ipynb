{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70674796",
   "metadata": {},
   "source": [
    "## BERT 임베딩 차원에서 유사도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe338c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gmleh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2c5a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057e2dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Generating embeddings: 100%|█████████████████████████████████████████████████████| 30522/30522 [15:11<00:00, 33.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model_name = \"bert-base-uncased\" # BERT와 FinBERT 비교\n",
    "# model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Get all tokens\n",
    "all_tokens = list(tokenizer.get_vocab().keys())\n",
    "\n",
    "# Dictionary to store all embeddings\n",
    "all_embeddings = {}\n",
    "\n",
    "# Generate embeddings\n",
    "for token in tqdm(all_tokens, desc=\"Generating embeddings\"):\n",
    "    tokenized = tokenizer(token, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized)\n",
    "    embeddings = torch.mean(outputs.last_hidden_state, dim=1).squeeze().numpy()\n",
    "    all_embeddings[token] = embeddings\n",
    "\n",
    "# Function to find most similar words\n",
    "def find_most_similar(word, num_similar=100):\n",
    "    if word not in all_embeddings:\n",
    "        print(\"Word not in vocabulary\")\n",
    "        return\n",
    "    \n",
    "    similarities = {}\n",
    "    target_embedding = all_embeddings[word]\n",
    "\n",
    "    for token, embedding in tqdm(all_embeddings.items(), desc=f\"Calculating similarities for {word}\"):\n",
    "        similarity = cosine_similarity(target_embedding, embedding)\n",
    "        similarities[token] = similarity\n",
    "\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_similarities[:num_similar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d5831d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarities for increase: 100%|██████████████████████████████████| 30522/30522 [00:00<00:00, 64793.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 words most similar to 'increase':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarities for decrease: 100%|██████████████████████████████████| 30522/30522 [00:00<00:00, 70308.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 words most similar to 'decrease':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# operate function : increase / decrease\n",
    "word1 = 'increase'\n",
    "word2 = 'decrease'\n",
    "variation_list = []\n",
    "\n",
    "most_similar_words1 = find_most_similar(word1)\n",
    "print(f\"Top 100 words most similar to '{word1}':\")\n",
    "\n",
    "for similar_word, similarity in most_similar_words1:\n",
    "    variation_list.append(similar_word)\n",
    "    \n",
    "most_similar_words2 = find_most_similar(word2)\n",
    "print(f\"Top 100 words most similar to '{word2}':\")\n",
    "\n",
    "for similar_word, similarity in most_similar_words2:\n",
    "    variation_list.append(similar_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fcbba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['increase', 'increases', 'promote', 'reduce', 'builds', 'modify', 'removes', 'extends', 'increasing', 'easing', 'improving', 'reduces', 'generate', 'suspend', 'lifts', 'drill', 'establish', 'ensured', 'removing', 'lowers', '明', 'repair', 'token', 'enhance', 'curses', 'promotes', 'accelerated', 'alleviate', 'neighborhood', 'levy', 'insignia', 'additions', 'organist', 'captains', 'enhancing', 'defining', 'bared', 'amendment', 'concealed', 'amplified', 'establishes', 'emblem', 'bomb', 'advertisement', 'opponent', 'created', 'exercises', 'worker', 'patch', 'appointing', 'boulevard', 'extend', '1625', 'revoked', 'quran', 'bearer', 'strikeouts', 'rescues', 'establishing', 'flaps', 'calculating', 'blouse', '33rd', 'aroused', '1886', 'concourse', 'operatives', '信', 'asserting', 'destroys', 'promoting', '秋', '1888', 'elector', 'inversion', 'exhibit', 'prelude', 'improve', 'noel', 'wept', 'decreasing', 'intimidation', 'develop', 'adjective', 'awakened', 'cooked', 'exodus', 'assassin', 'arresting', 'transmitter', 'reductions', 'preserving', 'necklace', 'repairing', 'indies', 'adviser', 'improvement', 'routines', 'destroying', '1711', 'decrease', 'decreases', 'pharaoh', 'observes', 'insulted', 'exposition', 'ي', 'ᵢ', 'tugs', 'ལ', 'therese', 'theorists', '我', 'authenticity', '1774', 'sahib', 'ව', 'misunderstanding', 'stairwell', 'modify', 'ancestor', '₤', 'believer', 'θ', 'windy', 'ambiguity', 'contradiction', '1761', 'convenience', '不', 'parasites', 'ね', 'comte', '州', 'nouns', 'य', 'onions', 'ₑ', 'ふ', 'prosperity', '法', 'intend', 'あ', 'parasite', 'raider', 'informing', 'ʲ', '家', 'monsieur', 'neighborhood', 'implementations', 'cornice', 'う', 'accomplishment', 'benji', 'murderers', 'v6', 'つ', '氵', '明', 'tonic', 'ვ', 'י', 'ய', 'blouse', 'に', 'chevy', '1771', 'adultery', '£10', 'φ', 'proposition', 'collisions', 'rudy', '生', 'rudolph', 'お', 'remarried', '♭', 'trailer', 'い', 'せ', 'viewer', 'stairway', 'milo', 'virtues', 'chords', 'satisfying', 'noisy', 'postdoctoral', 'sheppard', 'delight', 'خ', 'ammonia', 'turrets', 'idols', '幸', 'え', 'ז', 'witty']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_variation_list = [word for word in variation_list if word not in stop_words]\n",
    "\n",
    "print(filtered_variation_list)\n",
    "len(filtered_variation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f5bbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['informing',\n",
       " 'builds',\n",
       " 'convenience',\n",
       " 'therese',\n",
       " 'ვ',\n",
       " 'φ',\n",
       " 'promote',\n",
       " 'defining',\n",
       " 'virtues',\n",
       " 'created',\n",
       " 'enhance',\n",
       " 'assassin',\n",
       " '秋',\n",
       " 'extend',\n",
       " 'boulevard',\n",
       " 'easing',\n",
       " 'adultery',\n",
       " 'noel',\n",
       " 'accomplishment',\n",
       " 'delight',\n",
       " '♭',\n",
       " 'exercises',\n",
       " 'insulted',\n",
       " 'あ',\n",
       " 'reduces',\n",
       " 'prosperity',\n",
       " 'routines',\n",
       " 'ₑ',\n",
       " '1774',\n",
       " 'destroys',\n",
       " 'cornice',\n",
       " 'quran',\n",
       " 'decreasing',\n",
       " 'bearer',\n",
       " 'extends',\n",
       " 'believer',\n",
       " 'preserving',\n",
       " 'prelude',\n",
       " 'wept',\n",
       " 'rescues',\n",
       " '33rd',\n",
       " 'え',\n",
       " 'generate',\n",
       " 'adviser',\n",
       " 'sheppard',\n",
       " 'modify',\n",
       " 'stairwell',\n",
       " 'implementations',\n",
       " '1761',\n",
       " 'remarried',\n",
       " 'removes',\n",
       " 'reduce',\n",
       " 'neighborhood',\n",
       " 'ي',\n",
       " 'flaps',\n",
       " 'elector',\n",
       " 'token',\n",
       " 'repair',\n",
       " '1886',\n",
       " 'せ',\n",
       " 'insignia',\n",
       " 'witty',\n",
       " 'ʲ',\n",
       " 'v6',\n",
       " 'theorists',\n",
       " 'suspend',\n",
       " 'ambiguity',\n",
       " '州',\n",
       " '生',\n",
       " 'amplified',\n",
       " 'improving',\n",
       " 'intimidation',\n",
       " 'drill',\n",
       " 'establishes',\n",
       " 'arresting',\n",
       " '我',\n",
       " 'exposition',\n",
       " 'murderers',\n",
       " 'indies',\n",
       " 'satisfying',\n",
       " 'nouns',\n",
       " 'revoked',\n",
       " 'captains',\n",
       " 'ᵢ',\n",
       " 'increasing',\n",
       " 'rudolph',\n",
       " '1625',\n",
       " 'noisy',\n",
       " 'develop',\n",
       " 'calculating',\n",
       " 'つ',\n",
       " 'exodus',\n",
       " 'misunderstanding',\n",
       " 'chevy',\n",
       " 'tugs',\n",
       " 'trailer',\n",
       " '£10',\n",
       " 'raider',\n",
       " 'authenticity',\n",
       " 'increases',\n",
       " 'levy',\n",
       " 'ལ',\n",
       " '明',\n",
       " '氵',\n",
       " 'patch',\n",
       " 'ammonia',\n",
       " 'parasites',\n",
       " 'に',\n",
       " 'curses',\n",
       " 'repairing',\n",
       " '家',\n",
       " 'intend',\n",
       " 'opponent',\n",
       " '₤',\n",
       " 'onions',\n",
       " 'additions',\n",
       " 'strikeouts',\n",
       " 'transmitter',\n",
       " 'advertisement',\n",
       " 'improvement',\n",
       " 'parasite',\n",
       " 'θ',\n",
       " 'lifts',\n",
       " 'ふ',\n",
       " '幸',\n",
       " 'awakened',\n",
       " 'viewer',\n",
       " 'benji',\n",
       " 'stairway',\n",
       " 'ව',\n",
       " 'improve',\n",
       " 'pharaoh',\n",
       " 'inversion',\n",
       " 'concealed',\n",
       " 'worker',\n",
       " 'alleviate',\n",
       " 'enhancing',\n",
       " 'う',\n",
       " 'observes',\n",
       " '1771',\n",
       " 'increase',\n",
       " 'bared',\n",
       " 'destroying',\n",
       " 'sahib',\n",
       " 'blouse',\n",
       " 'rudy',\n",
       " 'appointing',\n",
       " 'ね',\n",
       " 'collisions',\n",
       " 'removing',\n",
       " 'emblem',\n",
       " 'य',\n",
       " 'tonic',\n",
       " 'monsieur',\n",
       " 'necklace',\n",
       " 'reductions',\n",
       " 'adjective',\n",
       " 'aroused',\n",
       " 'lowers',\n",
       " 'amendment',\n",
       " 'decrease',\n",
       " 'exhibit',\n",
       " 'bomb',\n",
       " 'ய',\n",
       " 'お',\n",
       " 'operatives',\n",
       " 'خ',\n",
       " 'turrets',\n",
       " 'decreases',\n",
       " '法',\n",
       " 'chords',\n",
       " 'concourse',\n",
       " 'ensured',\n",
       " 'promotes',\n",
       " 'cooked',\n",
       " 'idols',\n",
       " 'contradiction',\n",
       " '不',\n",
       " '1888',\n",
       " 'windy',\n",
       " 'postdoctoral',\n",
       " 'い',\n",
       " 'י',\n",
       " 'milo',\n",
       " 'establish',\n",
       " 'accelerated',\n",
       " 'establishing',\n",
       " 'proposition',\n",
       " 'organist',\n",
       " 'comte',\n",
       " '信',\n",
       " 'asserting',\n",
       " 'promoting',\n",
       " 'ancestor',\n",
       " 'ז',\n",
       " '1711']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_set = set(filtered_variation_list)\n",
    "len(variation_set)\n",
    "variation_list_dup = list(variation_set)\n",
    "variation_list_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ccdf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df11 = pd.DataFrame({'Name': variation_list_dup})\n",
    "df11.to_csv('LSTWORD_finbert.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1514ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(variation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "140b40ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['increasing',\n",
       " 'increases',\n",
       " 'decrease',\n",
       " 'reduce',\n",
       " 'adjust',\n",
       " 'decreased',\n",
       " 'expands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복된 단어 확인\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(variation_list)\n",
    "\n",
    "duplicate_words = [word for word, count in word_counts.items() if count > 1]\n",
    "\n",
    "duplicate_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c1062",
   "metadata": {},
   "source": [
    "## 단어가 포함된 문장만 살리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d544dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>bond yields hit record lows is a headline tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>first the 30year bond yield fell past 2% then ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>a few market veterans also recall bondmarket r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>and even fewer stuck their necks out then to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>today some of these early and prescient bond b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372395</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>the radio broadcasters restructuring plan eras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372396</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>it also transfers control of the company to ih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372397</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>franklin advisers inc. and its affiliates and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372398</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>chief executive bob pittman and chief financia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372399</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>san antoniobased iheart filed for bankruptcy i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2372400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Title  \\\n",
       "0        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "1        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "2        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "3        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "4        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "...                                                    ...   \n",
       "2372395  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "2372396  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "2372397  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "2372398  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "2372399  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "\n",
       "                                             Original_Text  \\\n",
       "0         Bond Yields Hit Record Lows is a headline tha...   \n",
       "1         Bond Yields Hit Record Lows is a headline tha...   \n",
       "2         Bond Yields Hit Record Lows is a headline tha...   \n",
       "3         Bond Yields Hit Record Lows is a headline tha...   \n",
       "4         Bond Yields Hit Record Lows is a headline tha...   \n",
       "...                                                    ...   \n",
       "2372395  iHeartMedia Inc. the nations largest radio bro...   \n",
       "2372396  iHeartMedia Inc. the nations largest radio bro...   \n",
       "2372397  iHeartMedia Inc. the nations largest radio bro...   \n",
       "2372398  iHeartMedia Inc. the nations largest radio bro...   \n",
       "2372399  iHeartMedia Inc. the nations largest radio bro...   \n",
       "\n",
       "                                                  Sentence  \n",
       "0         bond yields hit record lows is a headline tha...  \n",
       "1        first the 30year bond yield fell past 2% then ...  \n",
       "2        a few market veterans also recall bondmarket r...  \n",
       "3        and even fewer stuck their necks out then to d...  \n",
       "4        today some of these early and prescient bond b...  \n",
       "...                                                    ...  \n",
       "2372395  the radio broadcasters restructuring plan eras...  \n",
       "2372396  it also transfers control of the company to ih...  \n",
       "2372397  franklin advisers inc. and its affiliates and ...  \n",
       "2372398  chief executive bob pittman and chief financia...  \n",
       "2372399  san antoniobased iheart filed for bankruptcy i...  \n",
       "\n",
       "[2372400 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('textmining/concatenated_dataset_1003_v6.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae9b6219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering rows: 100%|██████████████████████████████████████████████████████| 2372400/2372400 [06:17<00:00, 6276.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def filter_rows_by_words_and_numbers(df, words_list):\n",
    "    tqdm.pandas(desc=\"Filtering rows\")\n",
    "    return df[df['Sentence'].progress_apply(lambda x: any(word in x.split() for word in words_list) or bool(re.search(r'\\d', x)))]\n",
    "\n",
    "filtered_df = filter_rows_by_words_and_numbers(df, variation_list_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e11e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>first the 30year bond yield fell past 2% then ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>a few market veterans also recall bondmarket r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>and even fewer stuck their necks out then to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>today some of these early and prescient bond b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yes Bonds Could Still Rally Even With Yields B...</td>\n",
       "      <td>Bond Yields Hit Record Lows is a headline tha...</td>\n",
       "      <td>i never bought bonds for yield he said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372388</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>the nations largest radio broadcaster said wed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372389</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>the company with 848 radio stations intends to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372390</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>the company could increase the offering size d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372394</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>the company has said it expects to exit from b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372395</th>\n",
       "      <td>Poised to Leave Bankruptcy iHeartMedia Files f...</td>\n",
       "      <td>iHeartMedia Inc. the nations largest radio bro...</td>\n",
       "      <td>the radio broadcasters restructuring plan eras...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1007746 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Title  \\\n",
       "1        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "2        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "3        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "4        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "7        Yes Bonds Could Still Rally Even With Yields B...   \n",
       "...                                                    ...   \n",
       "2372388  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "2372389  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "2372390  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "2372394  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "2372395  Poised to Leave Bankruptcy iHeartMedia Files f...   \n",
       "\n",
       "                                             Original_Text  \\\n",
       "1         Bond Yields Hit Record Lows is a headline tha...   \n",
       "2         Bond Yields Hit Record Lows is a headline tha...   \n",
       "3         Bond Yields Hit Record Lows is a headline tha...   \n",
       "4         Bond Yields Hit Record Lows is a headline tha...   \n",
       "7         Bond Yields Hit Record Lows is a headline tha...   \n",
       "...                                                    ...   \n",
       "2372388  iHeartMedia Inc. the nations largest radio bro...   \n",
       "2372389  iHeartMedia Inc. the nations largest radio bro...   \n",
       "2372390  iHeartMedia Inc. the nations largest radio bro...   \n",
       "2372394  iHeartMedia Inc. the nations largest radio bro...   \n",
       "2372395  iHeartMedia Inc. the nations largest radio bro...   \n",
       "\n",
       "                                                  Sentence  \n",
       "1        first the 30year bond yield fell past 2% then ...  \n",
       "2        a few market veterans also recall bondmarket r...  \n",
       "3        and even fewer stuck their necks out then to d...  \n",
       "4        today some of these early and prescient bond b...  \n",
       "7                  i never bought bonds for yield he said.  \n",
       "...                                                    ...  \n",
       "2372388  the nations largest radio broadcaster said wed...  \n",
       "2372389  the company with 848 radio stations intends to...  \n",
       "2372390  the company could increase the offering size d...  \n",
       "2372394  the company has said it expects to exit from b...  \n",
       "2372395  the radio broadcasters restructuring plan eras...  \n",
       "\n",
       "[1007746 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18cfad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 저장\n",
    "\n",
    "filtered_df.to_csv('textmining/filtered_df_small_ver1106.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revised_news_and_EDA.ipynb 파일로 가서 추가 전처리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
